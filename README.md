## Proyecto de Clasificaci√≥n de M√∫sica usando Aprendizaje por Refuerzo (RL)

√Årea: Aprendizaje por Refuerzo (Reinforcement Learning)
Sub√°rea: Clasificaci√≥n y Optimizaci√≥n
Problema: Clasificaci√≥n autom√°tica de canciones por g√©nero musical

- ¬øQu√© es el Aprendizaje por Refuerzo?
  El Aprendizaje por Refuerzo (RL) es una t√©cnica de Machine Learning que entrena agentes inteligentes para tomar decisiones mediante un enfoque de ensayo y error. A trav√©s de un sistema de recompensas y penalizaciones, el agente aprende progresivamente cu√°l es la mejor estrategia para lograr un objetivo.
  A diferencia del aprendizaje supervisado, donde se necesitan etiquetas expl√≠citas, en RL el agente aprende de su experiencia, ajustando sus decisiones en funci√≥n del entorno.

- Objetivos del Proyecto

1. Clasificaci√≥n con Aprendizaje por Refuerzo
   Desarrollar un agente RL capaz de clasificar canciones autom√°ticamente en g√©neros musicales (como rock, jazz, electr√≥nica, etc.), utilizando caracter√≠sticas extra√≠das de audio como:

   - Tempo (BPM)
   - Nivel de energ√≠a (RMS)
   - Centroide espectral
   - Coeficientes MFCC

2. Optimizaci√≥n de la Pol√≠tica de Clasificaci√≥n
   Implementar un proceso de optimizaci√≥n que permita al agente mejorar continuamente su pol√≠tica de decisi√≥n con base en las recompensas obtenidas. Esto permite:

   - Reducir errores de clasificaci√≥n.
   - Aprender estrategias m√°s eficientes sin supervisi√≥n directa.

- Relaci√≥n entre Clasificaci√≥n y Optimizaci√≥n en RL

  - Clasificaci√≥n: Es la tarea principal del agente, por ejemplo, etiquetar correctamente una canci√≥n como "rock".
  - Optimizaci√≥n: Es el proceso mediante el cual el agente ajusta su comportamiento para maximizar recompensas, es decir, mejorar la precisi√≥n de clasificaci√≥n con el tiempo.

  Mientras la clasificaci√≥n es lo que hace el agente, la optimizaci√≥n es c√≥mo lo mejora.

## Estructura del Proyecto

# Extracci√≥n de caracter√≠sticas de audio

Este comando permite procesar autom√°ticamente archivos .wav organizados por carpetas (donde cada carpeta representa un g√©nero musical), extraer caracter√≠sticas ac√∫sticas de cada canci√≥n usando librosa, y guardar los resultados en la base de datos a trav√©s del modelo SongFeature.

- C√≥mo usarlo
  python manage.py <nombre_del_comando> <ruta_a_datos> --workers <num_hilos>

  <nombre_del_comando>: Nombre del archivo del comando (sin .py).
  <ruta_a_datos>: Ruta al directorio principal que contiene carpetas por g√©nero, cada una con archivos .wav.
  --workers: (Opcional) N√∫mero de hilos para paralelizar el procesamiento. Por defecto: 4.

- Estructura esperada del directorio:
  dataset/
  ‚îÇ
  ‚îú‚îÄ‚îÄ rock/
  ‚îÇ ‚îú‚îÄ‚îÄ song1.wav
  ‚îÇ ‚îî‚îÄ‚îÄ song2.wav
  ‚îÇ
  ‚îú‚îÄ‚îÄ jazz/
  ‚îÇ ‚îú‚îÄ‚îÄ song3.wav
  ‚îÇ ‚îî‚îÄ‚îÄ song4.wav
  ‚îÇ
  ‚îî‚îÄ‚îÄ ...

- ¬øQu√© hace el comando paso a paso?

  1.  Recorre carpetas por g√©nero
      Cada subdirectorio dentro del data_path representa un g√©nero musical.
      Dentro de cada carpeta se procesan todos los archivos .wav.

  2.  Procesa cada canci√≥n
      Para cada archivo .wav, se realiza lo siguiente:
      Se carga el audio (en mono, a 22.050 Hz, hasta 30 segundos).
      Se extraen caracter√≠sticas ac√∫sticas con librosa:

      - tempo: ritmo estimado (en BPM).
      - rms: energ√≠a promedio del audio.
      - centroid: centroide espectral promedio (frecuencia central del espectro).
      - mfccs: 20 coeficientes cepstrales de Mel (MFCCs), promedio de cada uno.

      Se crea un diccionario con las caracter√≠sticas, el nombre del archivo y su g√©nero.

  3.  Evita duplicados
      Antes de procesar un archivo, verifica si ya existe en la base de datos usando su nombre (filename). Si ya fue procesado, lo omite.

  4.  Ejecuta en paralelo
      Usa ThreadPoolExecutor para procesar m√∫ltiples canciones al mismo tiempo, lo que acelera significativamente la ejecuci√≥n en grandes datasets. Tambi√©n muestra una barra de progreso con tqdm.

  5.  Guarda en la base de datos
      Filtra resultados v√°lidos (descarta errores y duplicados).

  - def add_arguments(self, parser):
    Permite que el comando reciba par√°metros personalizados cuando lo ejecutas con python manage.py.

    data_path (obligatorio): Ruta al directorio con subcarpetas por g√©nero.
    --workers (opcional): N√∫mero de hilos para procesar archivos en paralelo

- def process_song(self, file_path, genre):
  Procesa un solo archivo .wav para extraer sus caracter√≠sticas ac√∫sticas con librosa.
  Carga el archivo de audio (mono, 22050 Hz, duraci√≥n m√°xima de 30 s).

  Extrae:

  - tempo: velocidad o BPM.
  - rms: nivel de energ√≠a.
  - centroid: centro de gravedad del espectro de frecuencias.
  - mfccs: 20 coeficientes MFCC promedio.

  Devuelve un diccionario listo para guardarse en la base de datos.
  Evita duplicados: Si el archivo ya est√° registrado en el modelo SongFeature, lo omite.

- def handle(self, \*args, \*\*options):
  Es el m√©todo principal del comando, se ejecuta cuando usas el comando en consola.
  Lee los argumentos (data_path y workers) desde options.

  1. Busca todos los archivos .wav en las subcarpetas (g√©neros).
  2. Crea tareas para procesar cada archivo (jobs).
  3. Ejecuta esas tareas en paralelo usando ThreadPoolExecutor.
  4. Muestra barra de progreso con tqdm.
  5. Filtra resultados v√°lidos (descarta errores o duplicados).
  6. Guarda los datos en la base de datos en bloque (bulk_create).
  7. Muestra mensajes de √©xito o advertencia en consola.

# Entrenamiento de Agente - training.py

Este m√≥dulo permite entrenar un agente de Q-learning para clasificar canciones seg√∫n su g√©nero, usando las caracter√≠sticas previamente extra√≠das y guardadas en la base de datos Django a trav√©s del modelo SongFeature.

- C√≥mo usarlo
  Este m√©todo debe llamarse desde un entorno de desarrollo (como un script Python o vista Django):

  python manage.py shell

  > > > from rl_agent.training import train_agent
  > > > train_agent(episodes=5000)

- ¬øQu√© hace el entrenamiento paso a paso?

1. Carga datos desde la base de datos

   songs = SongFeature.objects.all()

   - Recupera todos los registros de canciones almacenados en la tabla SongFeatured

2. Identifica g√©neros √∫nicos

   genres = list(sorted(set(s.genre for s in songs)))
   genre_to_id = {g: i for i, g in enumerate(genres)}

   - Extrae una lista ordenada de los g√©neros disponibles en la base de datos.
   - Asigna un identificador entero a cada g√©nero (genre_to_id) para facilitar el entrenamiento.

3. Inicializa el agente de Q-learning

   agent = QLearningAgent(actions=genres)

   - Crea una instancia del agente, donde cada g√©nero es una acci√≥n que el agente puede tomar.

4. Prepara el conjunto de entrenamiento

   for song in songs:
   features = [song.tempo, song.rms, song.centroid, *song.mfccs]
   X.append(features)
   y.append(genre_to_id[song.genre])

   Para cada canci√≥n:
   Construye un vector con 23 caracter√≠sticas:

   - tempo: velocidad en BPM.
   - rms: energ√≠a del audio.
   - centroid: centroide espectral.
   - mfccs: 20 coeficientes MFCC.

   Guarda ese vector en X (datos de entrada).
   Almacena la etiqueta de g√©nero en y (como n√∫mero entero).

5. Entrena al agente por episodios

   for episode in range(episodes):
   ...

   Por cada episodio:

   - a. Se elige una canci√≥n aleatoriamente.
     idx = np.random.randint(0, len(X))

   - b. Se transforma su vector de caracter√≠sticas en un estado discreto:
     state = agent.discretize_state(X[idx])

   - c. El agente elige una acci√≥n (g√©nero) seg√∫n su pol√≠tica:
     action = agent.choose_action(state)

   - d. Se otorga una recompensa basada en si acert√≥ o no:
     reward = 1 if action == y[idx] else -1

   - e. Se calcula el siguiente estado como el de la siguiente canci√≥n (usando wrap-around):
     next_state = agent.discretize_state(X[(idx + 1) % len(X)])

   - f. El agente actualiza su Q-table aplicando la f√≥rmula de Q-learning:
     agent.learn(state, action, reward, next_state)

   - g. Se reduce epsilon gradualmente para disminuir la exploraci√≥n:
     agent.epsilon = max(0.01, agent.epsilon \* 0.995)

6. Guarda el agente entrenado

   agent.save(save_path)

   - Guarda la Q-table y los par√°metros del agente en un archivo .json.

7. Devuelve el agente

   return agent

   - Permite reutilizar el agente entrenado para hacer predicciones m√°s adelante.

# Entrenamiento de Agente - agent.py

La clase QLearningAgent implementa la l√≥gica de un agente que aprende con el algoritmo cl√°sico Q-learning. Puede discretizar estados, elegir acciones, aprender de recompensas, y guardar/cargar su conocimiento desde archivo.

¬øQu√© hace esta clase?

1. Inicializa el agente

   **init**(self, actions, alpha, gamma, epsilon)

   - actions: Lista de acciones posibles (g√©neros musicales).
   - alpha: Tasa de aprendizaje (0 a 1).
   - gamma: Factor de descuento (cu√°nto valora el futuro).
   - epsilon: Tasa de exploraci√≥n (probabilidad de tomar una acci√≥n aleatoria).
   - Crea una Q-table vac√≠a con un defaultdict, que se llena din√°micamente.

2. Convierte caracter√≠sticas en estados discretos

   discretize_state(features)

   - Divide cada caracter√≠stica (tempo, rms, centroid, mfccs) en 10 bins.
   - Convierte cada valor continuo en un bin entero.
   - Devuelve un tuple de enteros que representa el estado actual.
   - Este estado discreto puede usarse como clave en la Q-table.

3. Elige una acci√≥n con Œµ-greedy

   choose_action(state)

   - Con probabilidad epsilon: elige una acci√≥n aleatoria (explora).
   - Con probabilidad 1 - epsilon: elige la acci√≥n con mayor valor Q (explota).
   - Usa np.argmax(...) para encontrar la mejor acci√≥n conocida hasta el momento.

4. Actualiza la Q-table con lo aprendido

   learn(state, action, reward, next_state)

   - Calcula el valor futuro esperado del siguiente estado.
   - Usa la f√≥rmula:
     ùëÑ(ùë†,ùëé)‚ÜêùëÑ(ùë†,ùëé)+ùõº[ùëü- ùõæ ‚ãÖ max ùëé ùëÑ(ùë†‚Ä≤,ùëé‚Ä≤)‚àíùëÑ(ùë†,ùëé)] √≥ Q(s,a)‚ÜêQ(s,a)+Œ±[r+Œ≥‚ãÖ a max ‚Äã Q(s‚Ä≤,a‚Ä≤)‚àíQ(s,a)]
     - ¬øQu√© significa cada t√©rmino?
       S√≠mbolo -> Significado
       Q(s, a) -> Valor actual estimado de hacer acci√≥n a en estado s.
       r -> Recompensa obtenida por hacer esa acci√≥n.
       s' -> Estado siguiente (despu√©s de hacer la acci√≥n).
       a' -> Todas las acciones posibles en el siguiente estado.
       max Q(s', a') -> Mejor valor estimado desde el siguiente estado (valor futuro √≥ptimo).
       Œ± (alpha) -> Tasa de aprendizaje: cu√°nto peso damos a la nueva informaci√≥n (entre 0 y 1).
       Œ≥ (gamma) -> Factor de descuento: cu√°nto valoramos las recompensas futuras (tambi√©n entre 0 y 1).
   - Actualiza la Q-table incrementando el valor correspondiente a la acci√≥n tomada en el estado actual.

5. Guarda el modelo en disco

   save(path)

   - Convierte la Q-table (diccionario de tuplas ‚Üí listas) en un JSON y lo guarda junto con los par√°metros del agente.

6. Carga un modelo desde disco

   load(path)

   - Reconstruye un agente Q-learning desde un archivo .json, restaurando su Q-table y sus par√°metros originales.

# Endpoint - views.py

Este m√≥dulo implementa una vista Django (classify) que recibe un archivo de audio .wav, extrae sus caracter√≠sticas ac√∫sticas usando librosa, y utiliza un agente Q-learning previamente entrenado para predecir su g√©nero musical.

- C√≥mo usarlo
  M√©todo HTTP: POST
  Ruta: /classify (seg√∫n tu configuraci√≥n de urls.py)
  Encabezados requeridos: Ninguno especial
  Par√°metros:
  audio: archivo .wav subido como multipart/form-data.

- ¬øQu√© hace este m√≥dulo paso a paso?

1. Carga el agente de Q-learning
   AGENT = QLearningAgent.load('q_agent.json')

   - Al importar el m√≥dulo, se carga autom√°ticamente el agente entrenado desde el archivo q_agent.json.
   - Este agente contiene la Q-table y la lista de g√©neros que puede predecir.

2. Define la vista classify

   @csrf_exempt
   def classify(request):

   - La vista est√° exenta del token CSRF para permitir pruebas con herramientas como Postman o curl.
   - Solo responde a peticiones POST.

3. Valida y procesa el archivo recibido

   if request.method == 'POST' and request.FILES.get('audio'):

   - Verifica que:
     - La solicitud sea POST.
     - Contenga un archivo con clave audio.

4. Carga y preprocesa el audio

   y, sr = librosa.load(audio, sr=22050, mono=True)

   - Convierte el audio en un vector monoaural (y) con frecuencia de muestreo fija (sr = 22050 Hz).
   - Esto garantiza que todos los audios se analicen bajo las mismas condiciones.

5. Extrae las caracter√≠sticas ac√∫sticas

   features = [
   librosa.beat.beat_track(y=y, sr=sr)[0], # tempo (BPM)
   librosa.feature.rms(y=y).mean(), # rms (energ√≠a promedio)
   librosa.feature.spectral_centroid(y=y, sr=sr).mean(), # centroid (frecuencia promedio)
   \*librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20).mean(axis=1) # 20 MFCCs
   ]

   - Se extraen 23 caracter√≠sticas en total:
     1 tempo
     1 rms
     1 centroid
     20 MFCCs (media de cada uno)

curl.exe -X POST -F "audio=@C:\Users\usser\Documents\Proyectos\Clasificacion de Musicas\SongClassification-IA-1-2025\Backend\songClassifier\media\pop\pop.00016.wav" http://127.0.0.1:8000/classify/
